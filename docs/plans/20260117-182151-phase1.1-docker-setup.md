# Docker環境セットアップ計画 (Phase 1.1)

**作成日**: 2026-01-17
**対象**: 実装計画 Phase 1.1

---

## 概要

GTX 1660 SUPER (6GB VRAM) 環境でOllamaとSearXNGを動作させるDocker環境を構築する。

## 作成ファイル

```
local-deep-research/
├── docker-compose.yaml
├── .env (optional)
└── searxng/
    └── settings.yml
```

---

## 実装手順

### 1. searxng/settings.yml の作成

JSON API出力を有効化し、研究向け検索エンジンを設定:

**有効化するエンジン:**
- Google, Bing, DuckDuckGo（一般検索）
- Wikipedia, Wikidata（百科事典）
- Google News, Bing News（ニュース）
- Semantic Scholar, arXiv（学術研究）

**無効化するエンジン:**
- 画像・動画・地図・SNS系（テキスト研究に不要）

**重要設定:**
```yaml
search:
  formats:
    - html
    - json  # API利用に必須
server:
  limiter: false  # ローカル自動化用
```

### 2. docker-compose.yaml の作成

**Ollamaサービス:**
```yaml
ollama:
  image: ollama/ollama:latest
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
  environment:
    - OLLAMA_FLASH_ATTENTION=1  # VRAM効率化
    - OLLAMA_KEEP_ALIVE=24h     # モデル常駐
    - OLLAMA_HOST=0.0.0.0
  volumes:
    - ollama_data:/root/.ollama
  ports:
    - "11434:11434"
```

**SearXNGサービス:**
```yaml
searxng:
  image: searxng/searxng:latest
  volumes:
    - ./searxng:/etc/searxng:rw
  ports:
    - "8080:8080"
  deploy:
    resources:
      limits:
        memory: 1G
```

### 3. 動作確認コマンド

```bash
# サービス起動
docker compose up -d

# Ollamaヘルスチェック
curl http://localhost:11434/api/tags

# GPU認識確認
docker exec ollama nvidia-smi

# SearXNGヘルスチェック
curl "http://localhost:8080/healthz"

# JSON API テスト
curl "http://localhost:8080/search?q=test&format=json"
```

### 4. モデルのダウンロード

```bash
# Plannerモデル
docker exec ollama ollama pull deepseek-r1:7b

# Workerモデル
docker exec ollama ollama pull qwen2.5:3b

# 確認
docker exec ollama ollama list
```

---

## 変更対象ファイル

| ファイル | 操作 |
|---------|------|
| `searxng/settings.yml` | 新規作成 |
| `docker-compose.yaml` | 新規作成 |
| `.env` | 新規作成（オプション） |

---

## 検証チェックリスト

TDDが困難な外部依存のため、以下の手動チェックリストで確認:

### 前提条件
- [ ] NVIDIA Container Toolkitがインストール済み
- [ ] Docker / Docker Composeが利用可能

### Ollamaサービス
- [ ] コンテナが起動
- [ ] GPU認識 (`docker exec ollama nvidia-smi`)
- [ ] API応答 (`curl http://localhost:11434/api/tags`)
- [ ] `OLLAMA_FLASH_ATTENTION=1` 設定済み
- [ ] `OLLAMA_KEEP_ALIVE=24h` 設定済み

### SearXNGサービス
- [ ] コンテナが起動
- [ ] ヘルスチェック応答 (`/healthz`)
- [ ] JSON API動作 (`format=json` で結果取得)
- [ ] Google, Bing, DuckDuckGoエンジンが動作

### モデル
- [ ] `deepseek-r1:7b` ダウンロード済み
- [ ] `qwen2.5:3b` ダウンロード済み
- [ ] VRAMが6GB以内で動作

### 確認日時
- YYYY-MM-DD HH:mm: [PASS/FAIL]

---

## トラブルシューティング

### GPU認識されない場合
```bash
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

### SearXNGでJSON 403エラー
- `settings.yml` の `formats` に `json` が含まれているか確認
- コンテナを再起動: `docker compose restart searxng`

### VRAM不足
- 一度に1モデルのみロード
- Flash Attentionが有効か確認
